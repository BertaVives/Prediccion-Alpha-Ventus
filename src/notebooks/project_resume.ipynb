{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de la potencia generada en Alpha Ventus\n",
    "<p align=\"center\">\n",
    "<img src=\"https://www.whitecase.com/sites/default/files/images/hero/2022/11/offshore-wind-hero_0.jpg\" alt=\"drawing\" width=\"950\"/>\n",
    "</p>\n",
    "\n",
    "## Introducción\n",
    "El parque eólico marino Alpha Ventus es el primer parque eólico marino de Alemania. Está situado en el Mar del Norte y consta de doce turbinas, todas con una capacidad de cinco megavatios. En 2011, el parque eólico registro el factor de capacidad más alto de todos los parques eólicos marinos europeos. Sin embargo, dos años más tarde, este bajo un 10%. \n",
    "\n",
    "Se entiende como factor de capacidad la relación entre la salida real del generador de energía y su salida a plena capacidad; cuando más cercana sea la relación a 1:1, más estable será el sistema de energía. En otras palabras, es una métrica que se utiliza para describir la salida de un sistema de generación de energía.\n",
    "\n",
    "El objetivo de este proyecto es poder estimar la variación del factor de capacidad en los próximos años prediciendo la generación de energía a partir de ciertos parámetros obtenidos. \n",
    "\n",
    "### Visualización de los datos\n",
    "El dataset es una serie temporal compuesta por 49 columnas las cuales se dividen en aquellas que aportan información sobre factores externos como son la velocidad del viento o su dirección, por ejemplo, y aquellas que aportan información sobre los distintos sensores que tiene cada generador. Todas ellas, sin incluir la columna que indica el tiempo, son variables numéricas, es por ello que se fuerzan al tipo float64 y el tiempo al tipo datatime. Posteriormente, se realiza un pequeño reporte de las columnas, con sus tipos, tanto por ciento de missings y cardinalidad, que resultará muy útil de cara a la limpieza de los datos.\n",
    "\n",
    "## Limpieza de los datos\n",
    "Inicialmente, se realiza una primera reducción de las variables. Se eliminarán aquellas que no aporten ninguna información necesaria. Por un lado, desde un instante de tiempo al siguiente se va determinando los valores de velocidad del viento, dirección del viento, potencia activa y ángulo Yaw. Como consecuencia, se obtiene de cada variable la media de todos los valores detectados, la desviación estándar, el mínimo y el máximo. Para este proyecto los datos que interesan son aquellos que se encuentran en las columnas de la media, luego podemos eliminar las demás columnas. Por otro lado, las demás columnas contienen datos de los distintos sensores de los generadores, los cuales no aportan ninguna información útil para la predicción y se pueden eliminar.\n",
    "\n",
    "Una vez realizada la reducción de features preliminar, se modifica el nombre de las columnas restantes por uno más entendible y se procede al tratamiento de los valores nulos, outliers y duplicados.\n",
    "\n",
    "En primer lugar, se tratan los valores nulos. Estos pueden presentarse como valores NaN o 9999, por lo tanto, se deberán de imputar los dos tipos. Al tratarse de una serie temporal, estos no se pueden eliminar y se deberán imputar a un valor. Como las variables cambian su valor progresivamente a medida que transcurre el tiempo, los valores nulos se imputaran a su valor anterior. Las columnas WindSpeed, ActivePower y YawAngle poseen un valor nulo en la primera posición, luego se deberá imputar este por separado a su valor posterior.\n",
    "\n",
    "En segundo lugar, se procede a tratar los outliers. Los valores de las variables deben estar comprendidos dentro de un rango de valores, aquellos que se encuentren fuera de este rango se consideran outliers. En este dataset solo encontramos outliers en la velocidad del viento los cuales, al ser valores negativos, los imputamos a cero.\n",
    "\n",
    "Finalmente, se eliminan los valores duplicados. En este caso, todos los valores de tiempo lo están. Por ello, se elimina uno de ellos. Una vez eliminados, se modifican los valores de la columna tiempo para que todos sigan el formato 'yyyy-mm-dd hh:mm:ss'.\n",
    "\n",
    "## Exploratory Data Analysis - EDA\n",
    "Previamente al análisis de cada variable se hace un feature engineering. Primeramente, a partir de la columna del tiempo se van a crear tres más, las cuales determinaran la estación del año, el momento del día (mañana, tarde, noche o madrugada) y el año. Es entonces cuando se coloca la columna del tiempo como el índice del dataset. A continuación, se procede con las variables cíclicas. Una variable cíclica es aquella que se repite cíclicamente, como su nombre indica. Es fundamental asegurarse de que un modelo interpreta correctamente las características cíclicas, ya que, de lo contrario, la diferencia de dos horas entre 23 y 1 se interpretaría como -22. Para ello, debemos calcular el seno y el coseno de las variables cíclicas, en este caso la dirección del viento y el ángulo Yaw.\n",
    "\n",
    "Al empezar con el análisis, primero se grafica cada variable por separado para ver su distribución y, en el caso de las nuevas variables categóricas, para ver si su frecuencia es similar. Luego se grafica la velocidad y dirección del viento, la potencia y el ángulo en función del tiempo. Y, por último, se grafica cada variable en función del target que, en este caso, es la potencia.\n",
    "\n",
    "## Machine Learning\n",
    "Antes de probar cualquier modelo, se deben preparar los datos; se debe normalizar la velocidad del viento y transformar las variables no numéricas a numéricas. Hecho esto, se divide el dataset en x e y siendo y el target y x el dataset sin este. Por último, se hace la predicción utilizando más de un modelo.\n",
    "\n",
    "La variable a predecir es de tipo continúa, luego los modelos utilizados son de regresión. Para poder determinar con que modelo se obtiene una predicción más exacta, se han implementado diferentes tipos de algoritmos. Inicialmente, se han implementado dos algoritmos de regresión: regresión lineal y regresión polinomial de grado 4. Al ver que los resultados obtenidos no han sido los esperados, no se ha implementado la regresión de Lasso o de Ridge. A continuación, se ha implementado un algoritmo basado en instancia (k-Nearest Neighbor), un árbol de decisión, un algoritmo de ensembled (Random Forest), LightGBM y uno de boosting (XGBoost). En todo ellos se ha requerido determinar los parámetros para evitar overfitting.\n",
    "\n",
    "## Resultados y conclusiones\n",
    "\n",
    "## Futuros pasos\n",
    "- utilizar knnimputer: escrius a la memoria que has utilitzat aquest metode per temps de computacion i llavors suggereixes el knnimputer\n",
    "- utilizar modelos de redes neuronales como percepton y tambien modelo svm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b5a2aaf94a20ece0551648939ed853b4738d2f77c0cac11f174cba8f59e450c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
